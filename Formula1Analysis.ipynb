{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/23i368/Shalini/blob/main/Formula1Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n"
      ],
      "metadata": {
        "id": "MEZgbJniT0Mo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "loyyO8x2g-vf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "file_path = \"/content/drive/My Drive/DPL_Datasets/results.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "print(df.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "QxYimi8uhCKC",
        "outputId": "c4255a0b-5374-4fdd-f24f-ba70970ce685"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c489ce1a7d14>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/My Drive/DPL_Datasets/results.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_JfyD4mDX1R"
      },
      "outputs": [],
      "source": [
        "# Load all CSV files\n",
        "circuits = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/circuits.csv\")\n",
        "constructor_results = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/constructor_results.csv\")\n",
        "constructor_standings = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/constructor_standings.csv\")\n",
        "constructors = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/constructors.csv\")\n",
        "driver_standings = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/driver_standings.csv\")\n",
        "drivers = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/drivers.csv\")\n",
        "lap_times = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/lap_times.csv\")\n",
        "pit_stops = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/pit_stops.csv\")\n",
        "qualifying = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/qualifying.csv\")\n",
        "races = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/races.csv\")\n",
        "results = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/results.csv\")\n",
        "seasons = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/seasons.csv\")\n",
        "sprint_results = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/sprint_results.csv\")\n",
        "status = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/status.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data preprocessing**"
      ],
      "metadata": {
        "id": "K2UO2s9VI0sG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check first few rows of each dataset\n",
        "datasets = [circuits, constructor_results, constructor_standings, constructors, driver_standings,\n",
        "            drivers, lap_times, pit_stops, qualifying, races, results, seasons, sprint_results]\n",
        "\n",
        "for name, data in zip([\"circuits\", \"constructor_results\", \"constructor_standings\", \"constructors\",\n",
        "                        \"driver_standings\", \"drivers\", \"lap_times\", \"pit_stops\", \"qualifying\",\n",
        "                        \"races\", \"results\", \"seasons\", \"sprint_results\"], datasets):\n",
        "    print(f\"\\n{name}:\\n\", data.info(), \"\\n\", data.head())\n"
      ],
      "metadata": {
        "id": "oQRZrGPgFHA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking for missing values\n",
        "for name, data in zip([\"circuits\", \"constructor_results\", \"constructor_standings\", \"constructors\",\n",
        "                        \"driver_standings\", \"drivers\", \"lap_times\", \"pit_stops\", \"qualifying\",\n",
        "                        \"races\", \"results\", \"seasons\", \"sprint_results\"], datasets):\n",
        "    print(f\"\\n{name} Missing Values:\\n\", data.isnull().sum())\n"
      ],
      "metadata": {
        "id": "KRHD4coPFLRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, data in zip([\"circuits\", \"constructor_results\", \"constructor_standings\", \"constructors\",\n",
        "                        \"driver_standings\", \"drivers\", \"lap_times\", \"pit_stops\", \"qualifying\",\n",
        "                        \"races\", \"results\", \"seasons\", \"sprint_results\"], datasets):\n",
        "    print(f\"\\n{name} Missing Values:\\n\", data.isnull().sum())\n"
      ],
      "metadata": {
        "id": "-Ebk9WIZzG3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converting time columns to seconds for further processing\n",
        "def convert_to_seconds(time):\n",
        "  if type(time)==float:\n",
        "    return time\n",
        "  if time == \"\\\\N\": return np.nan\n",
        "  time = str(time).strip()\n",
        "  if \":\" in time:\n",
        "    minutes, seconds = map(float, time.split(':'))\n",
        "    return minutes * 60 + seconds\n",
        "qualifying[\"q1\"] = qualifying[\"q1\"].apply(convert_to_seconds)\n",
        "qualifying[\"q1\"] = qualifying[\"q1\"].fillna(qualifying[\"q1\"].median())\n",
        "qualifying[\"q2\"] = qualifying[\"q2\"].apply(convert_to_seconds)\n",
        "qualifying[\"q2\"] = qualifying[\"q2\"].fillna(qualifying[\"q2\"].median())\n",
        "qualifying[\"q3\"] = qualifying[\"q3\"].apply(convert_to_seconds)\n",
        "qualifying[\"q3\"] = qualifying[\"q3\"].fillna(qualifying[\"q3\"].median())\n",
        "print(qualifying[[\"q1\",\"q2\", \"q3\"]].head())\n"
      ],
      "metadata": {
        "id": "7IrCcFBZFvy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert date columns to datetime format\n",
        "races['date'] = pd.to_datetime(races['date'])\n",
        "seasons['year'] = seasons['year'].astype(int)\n",
        "\n",
        "# Convert categorical data to category type\n",
        "drivers['nationality'] = drivers['nationality'].astype('category')\n",
        "constructors['nationality'] = constructors['nationality'].astype('category')\n",
        "results['position'] = pd.to_numeric(results['position'], errors='coerce')\n"
      ],
      "metadata": {
        "id": "CmiYHM2cH1Ke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for duplicates\n",
        "for name, data in zip([\"circuits\", \"constructor_results\", \"constructor_standings\", \"constructors\",\n",
        "                        \"driver_standings\", \"drivers\", \"lap_times\", \"pit_stops\", \"qualifying\",\n",
        "                        \"races\", \"results\", \"seasons\", \"sprint_results\"], datasets):\n",
        "    print(f\"\\n{name} Duplicates:\", data.duplicated().sum())\n"
      ],
      "metadata": {
        "id": "K64EiPWsLUmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First, merge results with races and circuits\n",
        "race_results = results.merge(races, on=\"raceId\", how=\"left\", suffixes=(\"_results\", \"_races\"))\n",
        "race_results = race_results.merge(circuits, on=\"circuitId\", how=\"left\", suffixes=(\"_races\", \"_circuits\"))\n",
        "\n",
        "# Merge driver details\n",
        "race_results = race_results.merge(drivers, on=\"driverId\", how=\"left\", suffixes=(\"_circuits\", \"_drivers\"))\n",
        "\n",
        "# Merge constructor details\n",
        "race_results = race_results.merge(constructors, on=\"constructorId\", how=\"left\", suffixes=(\"_drivers\", \"_constructors\"))\n",
        "\n",
        "# Merge driver standings\n",
        "race_results = race_results.merge(driver_standings, on=[\"raceId\", \"driverId\"], how=\"left\", suffixes=(\"_constructors\", \"_driverStandings\"))\n",
        "\n",
        "# Merge constructor standings\n",
        "race_results = race_results.merge(constructor_standings, on=[\"raceId\", \"constructorId\"], how=\"left\", suffixes=(\"_driverStandings\", \"_constructorStandings\"))\n",
        "\n",
        "# Merge qualifying data\n",
        "race_results = race_results.merge(qualifying, on=[\"raceId\", \"driverId\", \"constructorId\"], how=\"left\", suffixes=(\"_constructorStandings\", \"_qualifying\"))\n",
        "\n",
        "# Merge results again (to ensure no missing values)\n",
        "race_results = race_results.merge(results, on=[\"raceId\", \"driverId\", \"constructorId\"], how=\"left\", suffixes=(\"_qualifying\", \"_finalResults\"))\n",
        "\n",
        "# Merge lap times (may contain multiple entries per driver per race)\n",
        "race_results = race_results.merge(lap_times, on=[\"raceId\", \"driverId\"], how=\"left\", suffixes=(\"_finalResults\",\"_lapTimes\"))\n",
        "\n",
        "# Merge pit stops (also multiple entries per driver per race)\n",
        "race_results = race_results.merge(pit_stops, on=[\"raceId\", \"driverId\"], how=\"left\")\n",
        "\n",
        "# Merge status (race finishing status)\n",
        "race_results = race_results.merge(status, left_on=\"statusId_finalResults\", right_on=\"statusId\", how=\"left\")\n",
        "\n",
        "# Drop redundant statusId column after merging\n",
        "race_results.drop(columns=[\"statusId_finalResults\", \"statusId\"], inplace=True)\n"
      ],
      "metadata": {
        "id": "zxFNF65aLYsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "race_results.columns"
      ],
      "metadata": {
        "id": "vFJNJHqfNinn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Engineering**"
      ],
      "metadata": {
        "id": "lAsFHxyEJqEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Driver Consistency (Avg finishing position)\n",
        "driver_avg_finish = race_results.groupby(\"driverId\")[\"position_finalResults\"].mean().reset_index()\n",
        "driver_avg_finish.rename(columns={\"position_finalResults\": \"avg_finishing_position\"}, inplace=True)\n",
        "\n",
        "driver_avg_qualifying = race_results.groupby(\"driverId\")[\"grid_finalResults\"].mean().reset_index()\n",
        "driver_avg_qualifying.rename(columns={\"grid_results\": \"avg_qualifying_position\"}, inplace=True)\n",
        "\n",
        "# Team Strength (Avg constructor points)\n",
        "constructor_avg_points = race_results.groupby(\"constructorId\")[\"points_finalResults\"].mean().reset_index()\n",
        "constructor_avg_points.rename(columns={\"points_finalResults\": \"avg_constructor_points\"}, inplace=True)\n",
        "\n",
        "\n",
        "# Track Complexity (Avg overtaking positions gained/lost)\n",
        "race_results[\"grid_change\"] = race_results[\"grid_finalResults\"] - race_results[\"position_finalResults\"]\n",
        "track_difficulty = race_results.groupby(\"circuitId\")[\"grid_change\"].mean().reset_index()\n",
        "track_difficulty.rename(columns={\"grid_change\": \"avg_positions_gained\"}, inplace=True)\n",
        "\n",
        "# Merge newly calculated features into the final dataset\n",
        "race_results = race_results.merge(driver_avg_finish, on=\"driverId\", how=\"left\")\n",
        "race_results = race_results.merge(constructor_avg_points, on=\"constructorId\", how=\"left\")\n",
        "race_results = race_results.merge(track_difficulty, on=\"circuitId\", how=\"left\")\n"
      ],
      "metadata": {
        "id": "LYzOGnLyMk2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop unnecessary columns (handling renamed columns)\n",
        "race_results.drop(columns=[\n",
        "    \"url_results\", \"url_races\", \"url_circuits\", \"url_drivers\",\n",
        "    \"url_constructors\", \"url_driverStandings\", \"url_constructorStandings\", \"url_qualifying\"\n",
        "], inplace=True, errors=\"ignore\")\n",
        "\n",
        "# Drop rows with remaining missing values\n",
        "race_results.dropna(inplace=True)\n",
        "\n",
        "# Save the cleaned dataset\n",
        "#race_results.to_csv(\"cleaned_f1_data.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "PRA7HVw-Prrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "race_results.columns"
      ],
      "metadata": {
        "id": "7Q45GsuGgzQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "#Team Strength\n",
        "constructor_avg_points = race_results.groupby(\"constructorId\")[\"points_finalResults\"].mean().reset_index()\n",
        "constructor_avg_points.rename(columns={\"points_results\": \"avg_constructor_points\"}, inplace=True)\n",
        "\n",
        "# Count total races and finished races (DNF is when position is NULL or 'DNF')\n",
        "constructor_races = race_results.groupby(\"constructorId\").size().reset_index(name=\"total_races\")\n",
        "\n",
        "constructor_wins = constructor_standings.groupby(\"constructorId\")[\"wins\"].sum().reset_index(name=\"wins\")\n",
        "# Merge race counts and wins for each constructor\n",
        "constructor_reliability = constructor_races.merge(constructor_wins, on=\"constructorId\", how=\"left\")\n",
        "constructor_reliability.fillna(0, inplace=True)\n",
        "# Compute reliability score as the percentage of races won\n",
        "constructor_reliability[\"win_reliability_score\"] = np.where(\n",
        "    constructor_reliability[\"total_races\"] > 0,\n",
        "    constructor_reliability[\"wins\"] / constructor_reliability[\"total_races\"],\n",
        "    0  # Ensure constructors with no races get a 0 reliability score\n",
        ")\n",
        "\n",
        "# Cap values between 0 and 1 for consistency\n",
        "constructor_reliability[\"win_reliability_score\"] = constructor_reliability[\"win_reliability_score\"].clip(0, 1)\n",
        "\n",
        "# Convert to percentage for better readability\n",
        "constructor_reliability[\"win_reliability_score\"] *= 100\n",
        "\n",
        "race_results = race_results.merge(constructor_avg_points, on=\"constructorId\", how=\"left\")\n",
        "race_results = race_results.merge(constructor_reliability, on=\"constructorId\", how=\"left\")\n"
      ],
      "metadata": {
        "id": "bwIl-ZSaSRvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure grid and positionOrder are numeric\n",
        "race_results[\"grid\"] = pd.to_numeric(race_results[\"grid_finalResults\"], errors=\"coerce\")\n",
        "race_results[\"positionOrder\"] = pd.to_numeric(race_results[\"positionOrder_finalResults\"], errors=\"coerce\")\n",
        "\n",
        "# Calculate positions gained/lost per driver per race\n",
        "race_results[\"positions_gained\"] = race_results[\"grid\"] - race_results[\"positionOrder_finalResults\"]\n",
        "\n",
        "# Compute the average overtakes per circuit\n",
        "track_overtaking = race_results.groupby(\"circuitId\")[\"positions_gained\"].mean().reset_index()\n",
        "track_overtaking.rename(columns={\"positions_gained\": \"avg_positions_gained\"}, inplace=True)\n",
        "\n",
        "# Merge with race_results\n",
        "race_results = race_results.merge(track_overtaking, on=\"circuitId\", how=\"left\")\n",
        "\n",
        "track_variability = race_results.groupby(\"circuitId\")[\"positions_gained\"].std().reset_index()\n",
        "track_variability.rename(columns={\"positions_gained\": \"position_variability\"}, inplace=True)\n",
        "\n",
        "# Merge with race_results\n",
        "race_results = race_results.merge(track_variability, on=\"circuitId\", how=\"left\")\n",
        "\n",
        "driver_variability = race_results.groupby(\"driverId\")[\"positions_gained\"].std().reset_index()\n",
        "driver_variability.rename(columns={\"positions_gained\": \"driver_position_variability\"}, inplace=True)\n",
        "\n",
        "# Merge with race_results\n",
        "race_results = race_results.merge(driver_variability, on=\"driverId\", how=\"left\")\n"
      ],
      "metadata": {
        "id": "8yqvc5_DgaLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "race_results.columns"
      ],
      "metadata": {
        "id": "xzJuTZD70hn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Performance correlation\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Select numeric columns for correlation analysis\n",
        "correlation_matrix = race_results[[\n",
        "    \"avg_constructor_points\", \"positions_gained\",\n",
        "    \"avg_positions_gained_y\", \"driver_position_variability\"\n",
        "]].corr()\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
        "plt.title(\"Performance Metric Correlations\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "N_L6qhkziDfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#constructor trends over years\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Aggregate constructor points over time\n",
        "constructor_trends = race_results.groupby([\"year\", \"name\"])[\"points_finalResults_y\"].sum().reset_index()\n",
        "\n",
        "# Identify the champion constructor for each year (highest points)\n",
        "champions = constructor_trends.loc[constructor_trends.groupby(\"year\")[\"points_finalResults_y\"].idxmax()]\n",
        "\n",
        "# Apply rolling average for smoother trends\n",
        "constructor_trends[\"points_smooth\"] = constructor_trends.groupby(\"name\")[\"points_finalResults_y\"].transform(lambda x: x.rolling(3, min_periods=1).mean())\n",
        "\n",
        "# Filter to show only top constructors (avoid clutter)\n",
        "constructor_totals = constructor_trends.groupby(\"name\")[\"points_finalResults_y\"].sum()\n",
        "top_constructors = constructor_totals[constructor_totals > 100].index  # Keep teams with >100 total points\n",
        "constructor_trends = constructor_trends[constructor_trends[\"name\"].isin(top_constructors)]\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(14, 7))\n",
        "sns.lineplot(x=\"year\", y=\"points_smooth\", hue=\"name\", data=constructor_trends, marker=\"o\", linewidth=2, alpha=0.85)\n",
        "\n",
        "# Annotate the champion constructor each year\n",
        "for _, row in champions.iterrows():\n",
        "    plt.text(row[\"year\"], row[\"points_finalResults_y\"] + 10, row[\"name\"],\n",
        "             fontsize=9, rotation=90, ha=\"right\", color=\"black\")\n",
        "\n",
        "# Customizations\n",
        "plt.title(\"Constructor Points Over the Years (With Champions)\", fontsize=14, fontweight=\"bold\")\n",
        "plt.xlabel(\"Year\", fontsize=12)\n",
        "plt.ylabel(\"Total Points (Smoothed)\", fontsize=12)\n",
        "plt.xticks(rotation=90)  # Rotate for better readability\n",
        "plt.yticks(fontsize=10)\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
        "\n",
        "# Improve legend placement\n",
        "plt.legend(title=\"Constructor\", bbox_to_anchor=(1.05, 1), loc=\"upper left\", fontsize=10, ncol=2)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "GagSGcvGiDcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#driver dominance\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "driver_points_history = race_results.groupby([\"year\", \"driverId\"])[\"points_finalResults_y\"].sum().reset_index()\n",
        "driver_points_history = driver_points_history.merge(drivers[[\"driverId\", \"forename\"]], on=\"driverId\", how=\"left\")\n",
        "\n",
        "plt.figure(figsize=(14, 7))\n",
        "\n",
        "# Line plot for driver performance per season\n",
        "sns.lineplot(x=\"year\", y=\"points_finalResults_y\", hue=\"forename\", data=driver_points_history,\n",
        "             marker=\"o\", linewidth=2, alpha=0.8, palette=\"tab10\")\n",
        "\n",
        "plt.title(\"Historical Driver Dominance (Total Points Per Season)\", fontsize=14, fontweight=\"bold\")\n",
        "plt.xlabel(\"Year\", fontsize=12)\n",
        "plt.ylabel(\"Total Points\", fontsize=12)\n",
        "\n",
        "plt.legend(title=\"Driver\", bbox_to_anchor=(1.02, 1), loc=\"upper left\", fontsize=10,ncol=5)\n",
        "\n",
        "# Highlighting season champions\n",
        "season_champions = driver_points_history.loc[driver_points_history.groupby(\"year\")[\"points_finalResults_y\"].idxmax()]\n",
        "for _, row in season_champions.iterrows():\n",
        "    plt.text(row[\"year\"], row[\"points_finalResults_y\"] + 5, row[\"forename\"],\n",
        "             fontsize=9, color=\"black\", ha=\"center\", rotation=90, fontweight=\"bold\")\n",
        "\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "XoWcalMgkAqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#strategic pitshop\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Group by race and compute average pit stops\n",
        "pit_stop_analysis = race_results.groupby([\"raceId\"])[\"stop\"].mean().reset_index()\n",
        "pit_stop_analysis.rename(columns={\"stop\": \"avg_pit_stops\"}, inplace=True)\n",
        "\n",
        "# Line Plot\n",
        "plt.figure(figsize=(14, 6))\n",
        "sns.lineplot(data=pit_stop_analysis, x=\"raceId\", y=\"avg_pit_stops\", marker=\"o\", linestyle=\"-\", color=\"b\")\n",
        "plt.title(\"Trend of Average Pit Stops per Race\")\n",
        "plt.xlabel(\"Race ID\")\n",
        "plt.ylabel(\"Average Pit Stops\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "# Get the race with the maximum average pit stops\n",
        "max_pit_stop_race = pit_stop_analysis.loc[pit_stop_analysis[\"avg_pit_stops\"].idxmax()]\n",
        "print(max_pit_stop_race)\n",
        "\n",
        "# Fetch the average points for that race\n",
        "max_race_points_avg = race_results.loc[race_results[\"raceId\"] == max_pit_stop_race[\"raceId\"], \"points_finalResults_y\"].mean()\n",
        "print(\"Average Points for max pit stop race:\", max_race_points_avg)\n",
        "\n",
        "# Get the race with the minimum average pit stops\n",
        "min_pit_stop_race = pit_stop_analysis.loc[pit_stop_analysis[\"avg_pit_stops\"].idxmin()]\n",
        "print(min_pit_stop_race)\n",
        "\n",
        "# Fetch the average points for that race\n",
        "min_race_points_avg = race_results.loc[race_results[\"raceId\"] == min_pit_stop_race[\"raceId\"], \"points_finalResults_y\"].mean()\n",
        "print(\"Average Points for min pit stop race:\", min_race_points_avg)\n",
        "##inference: Fewer Pit stops makes the race outcome better."
      ],
      "metadata": {
        "id": "PohIkf_5iDZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x=\"stop\", y=\"positions_gained\", data=race_results)\n",
        "plt.xlabel(\"Total Pit Stops\")\n",
        "plt.ylabel(\"Positions Gained/Lost\")\n",
        "plt.title(\"Distribution of Position Changes by Pit Stops\")\n",
        "plt.axhline(0, color=\"red\", linestyle=\"--\")  # Reference line\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "## more the pit stops the position loss is high"
      ],
      "metadata": {
        "id": "nk9p2vl3iDW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Team wise pit stop efficiency\n",
        "team_pit_stops = race_results.groupby(\"constructorId\")[\"stop\"].mean().reset_index()\n",
        "team_pit_stops.rename(columns={\"stop\": \"avg_pit_stops\"}, inplace=True)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=\"constructorId\", y=\"avg_pit_stops\", data=team_pit_stops, palette=\"viridis\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.title(\"Average Pit Stops per Team\")\n",
        "plt.xlabel(\"Constructor ID\")\n",
        "plt.ylabel(\"Average Pit Stops\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Vc5jmF_ZiDUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "sns.scatterplot(x=\"name\",\n",
        "                y=\"win_reliability_score\",\n",
        "                data=race_results,\n",
        "                alpha=0.7,\n",
        "                palette=\"coolwarm\",\n",
        "                edgecolor=\"black\")\n",
        "\n",
        "plt.title(\"Constructor Win Reliability vs. Points\")\n",
        "plt.xlabel(\"Win Reliability Score (Races Won %)\")\n",
        "plt.ylabel(\"Final Race Points\")\n",
        "\n",
        "plt.xticks(rotation=90)\n",
        "plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1), title=\"Constructor\")\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "X6dtbktEiDRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Team dynamics\n",
        "team_performance = race_results.groupby([\"constructorId\", \"driverId\"])[\"points_finalResults_y\"].mean().reset_index()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x=\"constructorId\", y=\"points_finalResults_y\", data=team_performance)\n",
        "plt.xticks(rotation=45)\n",
        "plt.title(\"Points Distribution Within Teams (Teammates Comparison)\")\n",
        "plt.xlabel(\"Constructor ID\")\n",
        "plt.ylabel(\"Average Points\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "n_bti3bdiDGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Diver adaptability\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x=\"circuitId\", y=\"driver_position_variability\", data=race_results)\n",
        "plt.xticks(rotation=45)\n",
        "plt.title(\"Driver Performance Variability by Circuit\")\n",
        "plt.xlabel(\"Circuit ID\")\n",
        "plt.ylabel(\"Performance Variability (Lower is Better)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vCZ_2JngiC13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Load Dataset\n",
        "race_results = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/results.csv\")\n",
        "\n",
        "# Define Features (Ensure 'positionOrder' is the target variable)\n",
        "# X = race_results.drop(columns=['positionOrder'], errors='ignore')\n",
        "# y = race_results['positionOrder']\n",
        "X = race_results[[\"driverId\", \"constructorId\", \"grid\", \"laps\", \"fastestLap\", \"points\"]]\n",
        "y = race_results[\"positionOrder\"]  # Target variable\n",
        "\n",
        "for col in X:\n",
        "  print(col,X[col].dtype)\n",
        "# Identify categorical columns\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Convert categorical columns using Label Encoding\n",
        "label_encoders = {}\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    X[col] = le.fit_transform(X[col])  # Convert categorical values to numbers\n",
        "    label_encoders[col] = le  # Store label encoder for future reference\n",
        "\n",
        "# Standardize Features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Model\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate Model\n",
        "print(\"Mean Absolute Error (MAE):\", mean_absolute_error(y_test, y_pred))\n",
        "print(\"Mean Squared Error (MSE):\", mean_squared_error(y_test, y_pred))\n",
        "print(\"Root Mean Squared Error (RMSE):\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print(\"RÂ² Score:\", r2_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "NnRRjLp2Wr-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_race_data_1 = {\n",
        "    \"driverId\": 10,  # Known driver\n",
        "    \"constructorId\": 7,\n",
        "    \"grid\": 18,  # Mid-grid start\n",
        "    \"laps\": 43,  # Full race distance\n",
        "    \"fastestLap\": 213.166,  # Fast lap in seconds\n",
        "    \"points\": 0  # Scored decent points in previous races\n",
        "}\n",
        "\n",
        "new_race_data_2 = {\n",
        "    \"driverId\": 999,  # Unseen driver\n",
        "    \"constructorId\": 888,  # Unseen constructor\n",
        "    \"grid\": 10,\n",
        "    \"laps\": 50,\n",
        "    \"fastestLap\": 92.345,\n",
        "    \"points\": 5  # Low points from past races\n",
        "}\n",
        "\n",
        "new_race_data_3 = {\n",
        "    \"driverId\": 5,\n",
        "    \"constructorId\": 3,\n",
        "    \"grid\": 20,  # Last position start\n",
        "    \"laps\": 30,  # Retired early or safety car issues\n",
        "    \"fastestLap\": 95.567,\n",
        "    \"points\": 0  # No previous points\n",
        "}\n",
        "\n",
        "new_race_data_4 = {\n",
        "    \"driverId\": 1,\n",
        "    \"constructorId\": 2,\n",
        "    \"grid\": 1,  # Pole position\n",
        "    \"laps\": 53,  # More than standard race laps (overtime scenario)\n",
        "    \"fastestLap\": 88.999,  # Fastest lap\n",
        "    \"points\": 25  # Max points from previous race\n",
        "}\n",
        "\n",
        "test_cases = [new_race_data_1, new_race_data_2, new_race_data_3, new_race_data_4]\n",
        "\n",
        "for i, test_data in enumerate(test_cases):\n",
        "    test_df = pd.DataFrame([test_data])\n",
        "\n",
        "    # Encode categorical features safely\n",
        "    for col, le in label_encoders.items():\n",
        "        test_df[col] = test_df[col].apply(lambda x: le.transform([x])[0] if x in le.classes_ else -1)\n",
        "\n",
        "    # Standardize numerical features\n",
        "    test_scaled = scaler.transform(test_df)\n",
        "\n",
        "    # Predict race position\n",
        "    predicted_position = model.predict(test_scaled)\n",
        "    print(f\"Test Case {i+1}: Predicted Finishing Position = {int(round(predicted_position[0]))}\")\n"
      ],
      "metadata": {
        "id": "4QODceBnbuea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# ---- Cross-Validation ----\n",
        "# Perform 5-fold cross-validation using negative MAE (we take the negative because higher scores mean better performance)\n",
        "cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring=\"neg_mean_absolute_error\")\n",
        "print(\"Cross-Validation MAE Scores:\", -cv_scores)\n",
        "print(\"Mean Cross-Validation MAE:\", -cv_scores.mean())\n",
        "\n",
        "# ---- Residual Plot ----\n",
        "# Calculate residuals (difference between actual and predicted values)\n",
        "residuals = y_test - y_pred\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_pred, residuals, alpha=0.7)\n",
        "plt.axhline(y=0, color='red', linestyle='--')\n",
        "plt.xlabel(\"Predicted Values\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.title(\"Residual Plot\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "feature_importances = model.feature_importances_\n",
        "feature_names = X.columns  # Ensure this is the DataFrame used to create X_scaled\n",
        "\n",
        "\n",
        "indices = np.argsort(feature_importances)[::-1]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.title(\"Feature Importances\")\n",
        "plt.bar(range(len(feature_importances)), feature_importances[indices], align=\"center\")\n",
        "plt.xticks(range(len(feature_importances)), np.array(feature_names)[indices], rotation=90)\n",
        "plt.xlabel(\"Feature Names\")\n",
        "plt.ylabel(\"Importance Score\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Bo2AwCcPZ1Ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**PS - 1**"
      ],
      "metadata": {
        "id": "6f9Uf-VOG56a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#PS-1\n",
        "import pandas as pd\n",
        "\n",
        "results = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/results.csv\")\n",
        "drivers = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/drivers.csv\")\n",
        "constructors = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/constructors.csv\")\n",
        "\n",
        "results['win'] = results['positionOrder'].apply(lambda x: 1 if x == 1 else 0)\n",
        "results['podium'] = results['positionOrder'].apply(lambda x: 1 if x <= 3 else 0)\n",
        "\n",
        "driver_perf = results.groupby('driverId').agg(total_races=('raceId', 'count'),\n",
        "                                              wins=('win', 'sum'),\n",
        "                                              podiums=('podium', 'sum'),\n",
        "                                              total_points=('points', 'sum')).reset_index()\n",
        "driver_perf['win_ratio'] = driver_perf['wins'] / driver_perf['total_races']\n",
        "driver_perf = pd.merge(driver_perf, drivers[['driverId','forename','surname']], on='driverId', how='left')\n",
        "driver_perf['driver'] = driver_perf['forename'] + \" \" + driver_perf['surname']\n",
        "\n",
        "constructor_perf = results.groupby('constructorId').agg(total_races=('raceId', 'count'),\n",
        "                                                         wins=('win', 'sum'),\n",
        "                                                         podiums=('podium', 'sum')).reset_index()\n",
        "constructor_perf['win_ratio'] = constructor_perf['wins'] / constructor_perf['total_races']\n",
        "constructor_perf = pd.merge(constructor_perf, constructors[['constructorId','name']], on='constructorId', how='left')\n"
      ],
      "metadata": {
        "id": "FoPjB1tiuPjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display top 10 dominant drivers\n",
        "top_drivers = driver_perf.sort_values('win_ratio', ascending=False).head(10)\n",
        "print(\"\\nðŸŽï¸ **Top 10 Dominant Drivers (by Win Ratio)** ðŸ†\")\n",
        "for i, row in top_drivers.iterrows():\n",
        "    print(f\"{i+1}. {row['driver']} - Win Ratio: {row['win_ratio']:.2%}, Wins: {row['wins']}, Podiums: {row['podiums']}\")\n",
        "\n",
        "# Display top 10 dominant constructors\n",
        "top_constructors = constructor_perf.sort_values('win_ratio', ascending=False).head(10)\n",
        "print(\"\\nðŸŽï¸ **Top 10 Dominant Constructors (by Win Ratio)** ðŸ†\")\n",
        "for i, row in top_constructors.iterrows():\n",
        "    print(f\"{i+1}. {row['name']} - Win Ratio: {row['win_ratio']:.2%}, Wins: {row['wins']}, Podiums: {row['podiums']}\")\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=\"win_ratio\", y=\"driver\", data=top_drivers, palette=\"coolwarm\")\n",
        "\n",
        "plt.title(\"ðŸŽï¸ Top 10 Dominant Drivers (Win Ratio)\", fontsize=14)\n",
        "plt.xlabel(\"Win Ratio\", fontsize=12)\n",
        "plt.ylabel(\"Driver\", fontsize=12)\n",
        "plt.xlim(0, 1)\n",
        "plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.5)\n",
        "\n",
        "for index, value in enumerate(top_drivers[\"win_ratio\"]):\n",
        "    plt.text(value, index, f\"{value:.2%}\", va=\"center\", fontsize=10)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=\"win_ratio\", y=\"name\", data=top_constructors, palette=\"magma\")\n",
        "\n",
        "plt.title(\"ðŸŽï¸ Top 10 Dominant Constructors (Win Ratio)\", fontsize=14)\n",
        "plt.xlabel(\"Win Ratio\", fontsize=12)\n",
        "plt.ylabel(\"Constructor\", fontsize=12)\n",
        "plt.xlim(0, 1)\n",
        "plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.5)\n",
        "\n",
        "for index, value in enumerate(top_constructors[\"win_ratio\"]):\n",
        "    plt.text(value, index, f\"{value:.2%}\", va=\"center\", fontsize=10)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hBahKP6eE878"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "results = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/results.csv\")\n",
        "\n",
        "# Compute driver statistics\n",
        "driver_stats = results.groupby('driverId').agg(\n",
        "    career_races=('raceId', 'nunique'),\n",
        "    wins=('positionOrder', lambda x: (x == 1).sum()),\n",
        "    podiums=('positionOrder', lambda x: (x <= 3).sum()),\n",
        "    total_points=('points', 'sum')\n",
        ").reset_index()\n",
        "\n",
        "# Compute correlation\n",
        "corr = driver_stats[['career_races', 'wins', 'podiums', 'total_points']].corr()\n",
        "\n",
        "# ðŸ”¥ Heatmap of correlations\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(corr, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
        "\n",
        "plt.title(\"Correlation: Career Longevity vs Wins, Podiums, and Total Points\", fontsize=14)\n",
        "plt.xticks(rotation=45)\n",
        "plt.yticks(rotation=0)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "AAAr3w7puv_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PS - 2**"
      ],
      "metadata": {
        "id": "Y3-hItP3HMoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "results = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/results.csv\")\n",
        "drivers = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/drivers.csv\")\n",
        "\n",
        "# Compute position change\n",
        "results['position_change'] = results['grid'] - results['positionOrder']\n",
        "\n",
        "# Calculate average position change per driver\n",
        "driver_position_gain = results.groupby('driverId').agg(\n",
        "    avg_position_gain=('position_change', 'mean'),\n",
        "    total_races=('raceId', 'count')\n",
        ").reset_index()\n",
        "\n",
        "# Merge with driver names\n",
        "driver_position_gain = pd.merge(driver_position_gain, drivers[['driverId', 'forename', 'surname']], on='driverId', how='left')\n",
        "driver_position_gain = pd.merge(driver_position_gain, results[['driverId','grid']].drop_duplicates(), on='driverId', how='left')\n",
        "driver_position_gain['driver'] = driver_position_gain['forename'] + \" \" + driver_position_gain['surname']\n",
        "\n",
        "# Drivers Who Excel at Gaining Positions\n",
        "top_movers = driver_position_gain.sort_values('avg_position_gain', ascending=False).head(10)\n",
        "print(\"Top 10 Drivers Who Gain the Most Positions:\")\n",
        "print(top_movers[['driver','grid', 'avg_position_gain', 'total_races']])\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x=results[\"grid\"], y=results[\"position_change\"], palette=\"coolwarm\")\n",
        "plt.title(\"Distribution of Position Gains/Losses by Grid Position\", fontsize=14)\n",
        "plt.xlabel(\"Starting Grid Position\", fontsize=12)\n",
        "plt.ylabel(\"Position Change (Gain/Loss)\", fontsize=12)\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "l4yoIbWoHxTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PS - 3**"
      ],
      "metadata": {
        "id": "hT7BPc4NI7rz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load datasets\n",
        "results = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/results.csv\")\n",
        "pit_stops = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/pit_stops.csv\")\n",
        "drivers = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/drivers.csv\")\n",
        "\n",
        "# Merge pit stops data with race results\n",
        "race_pit_data = pd.merge(pit_stops, results[['raceId', 'driverId', 'positionOrder']], on=['raceId', 'driverId'])\n",
        "\n",
        "# Calculate total pit stops per driver per race\n",
        "pit_counts = race_pit_data.groupby(['raceId', 'driverId']).agg(total_pit_stops=('stop', 'count')).reset_index()\n",
        "\n",
        "# Merge pit stop counts with final race positions\n",
        "race_analysis = pd.merge(pit_counts, results[['raceId', 'driverId', 'positionOrder']], on=['raceId', 'driverId'])\n",
        "\n",
        "# Analyze the relationship between pit stops and finishing position\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x=\"total_pit_stops\", y=\"positionOrder\", data=race_analysis, palette=\"coolwarm\")\n",
        "plt.title(\"Pit Stops vs. Final Race Position\")\n",
        "plt.xlabel(\"Number of Pit Stops\")\n",
        "plt.ylabel(\"Final Race Position (Lower is Better)\")\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "plt.show()\n",
        "\n",
        "# Analyze pit stop efficiency\n",
        "race_pit_data['pit_stop_time'] = pd.to_numeric(race_pit_data['milliseconds']) / 1000  # Convert to seconds\n",
        "pit_efficiency = race_pit_data.groupby('driverId').agg(avg_pit_time=('pit_stop_time', 'mean'), total_pit_stops=('stop', 'count')).reset_index()\n",
        "\n",
        "# Merge with driver names\n",
        "pit_efficiency = pd.merge(pit_efficiency, drivers[['driverId', 'forename', 'surname']], on='driverId', how='left')\n",
        "pit_efficiency['driver'] = pit_efficiency['forename'] + \" \" + pit_efficiency['surname']\n",
        "\n",
        "# Top 10 fastest pit stop drivers\n",
        "fastest_pit_stops = pit_efficiency.sort_values(\"avg_pit_time\", ascending=True).head(10)\n",
        "print(\"Top 10 Fastest Pit Stop Drivers:\")\n",
        "print(fastest_pit_stops[['driver', 'avg_pit_time', 'total_pit_stops']])\n",
        "\n",
        "# Fastest Pit Stop Drivers\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(y=fastest_pit_stops[\"driver\"], x=fastest_pit_stops[\"avg_pit_time\"], palette=\"coolwarm\", edgecolor=\"black\")\n",
        "plt.title(\"Top 10 Fastest Pit Stop Drivers\", fontsize=14)\n",
        "plt.xlabel(\"Average Pit Stop Time (Seconds)\", fontsize=12)\n",
        "plt.ylabel(\"Driver\", fontsize=12)\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "q5iAaXWxJarY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PS - 4**"
      ],
      "metadata": {
        "id": "GduRYg5eJwYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the datasets\n",
        "results = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/results.csv\")\n",
        "drivers = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/drivers.csv\")\n",
        "\n",
        "# Self-join to compare drivers in the same race\n",
        "rivalry_df = results.merge(results, on=\"raceId\", suffixes=(\"_A\", \"_B\"))\n",
        "\n",
        "# Keep only cases where two different drivers competed in the same race\n",
        "rivalry_df = rivalry_df[rivalry_df[\"driverId_A\"] != rivalry_df[\"driverId_B\"]]\n",
        "\n",
        "# Determine who finished ahead\n",
        "rivalry_df[\"driver_A_wins\"] = (rivalry_df[\"positionOrder_A\"] < rivalry_df[\"positionOrder_B\"]).astype(int)\n",
        "\n",
        "# Group by driver pair to count head-to-head wins\n",
        "head_to_head = rivalry_df.groupby([\"driverId_A\", \"driverId_B\"]).agg(\n",
        "    races_competed=(\"raceId\", \"count\"),\n",
        "    driver_A_wins=(\"driver_A_wins\", \"sum\")\n",
        ").reset_index()\n",
        "\n",
        "# Compute win ratio\n",
        "head_to_head[\"driver_A_win_ratio\"] = head_to_head[\"driver_A_wins\"] / head_to_head[\"races_competed\"]\n",
        "\n",
        "# Filter for significant rivalries (minimum races together)\n",
        "head_to_head = head_to_head[head_to_head[\"races_competed\"] > 100]\n",
        "\n",
        "# Merge driver names\n",
        "drivers[\"driver\"] = drivers[\"forename\"] + \" \" + drivers[\"surname\"]\n",
        "head_to_head = head_to_head.merge(drivers[[\"driverId\", \"driver\"]], left_on=\"driverId_A\", right_on=\"driverId\", how=\"left\").rename(columns={\"driver\": \"Driver_A\"})\n",
        "head_to_head = head_to_head.merge(drivers[[\"driverId\", \"driver\"]], left_on=\"driverId_B\", right_on=\"driverId\", how=\"left\").rename(columns={\"driver\": \"Driver_B\"})\n",
        "\n",
        "# Create driver pair column\n",
        "head_to_head[\"driver_pair\"] = head_to_head[\"Driver_A\"] + \" vs. \" + head_to_head[\"Driver_B\"]\n",
        "\n",
        "# Filter for competitive rivalries (win ratios close to 50-50)\n",
        "competitive_rivalries = head_to_head[head_to_head[\"driver_A_win_ratio\"] == 0.5]\n",
        "print(\"Most Competitive F1 Rivalries (Head-to-Head Win Ratios):\")\n",
        "print(competitive_rivalries[[\"driver_pair\", \"races_competed\", \"driver_A_win_ratio\"]])\n",
        "\n",
        "# Plot head-to-head win ratios\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=\"driver_pair\", y=\"driver_A_win_ratio\", data=competitive_rivalries, palette=\"coolwarm\")\n",
        "\n",
        "plt.title(\"Most Competitive F1 Rivalries (Win Ratios Close to 50%)\")\n",
        "plt.xlabel(\"Driver Rivalry\")\n",
        "plt.ylabel(\"Win Ratio of Driver A\")\n",
        "plt.xticks(rotation=90, ha=\"right\")\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "d81TXFXtMnMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PS - 5**"
      ],
      "metadata": {
        "id": "j5EaHwPCOkSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load datasets\n",
        "results = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/results.csv\")\n",
        "drivers = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/drivers.csv\")\n",
        "constructors = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/constructors.csv\")\n",
        "\n",
        "# Find top-performing driver for each team\n",
        "top_drivers = results.groupby([\"constructorId\", \"driverId\"])[\"points\"].sum().reset_index()\n",
        "top_drivers = top_drivers.sort_values([\"constructorId\", \"points\"], ascending=[True, False])\n",
        "\n",
        "# Get the best driver per team\n",
        "top_driver_per_team = top_drivers.groupby(\"constructorId\").first().reset_index()\n",
        "\n",
        "# Merge driver names\n",
        "top_driver_per_team = top_driver_per_team.merge(drivers[[\"driverId\", \"forename\", \"surname\"]], on=\"driverId\", how=\"left\")\n",
        "top_driver_per_team[\"driver_name\"] = top_driver_per_team[\"forename\"] + \" \" + top_driver_per_team[\"surname\"]\n",
        "\n",
        "# Merge constructor names\n",
        "top_driver_per_team = top_driver_per_team.merge(constructors[[\"constructorId\", \"name\"]], on=\"constructorId\", how=\"left\")\n",
        "top_driver_per_team = top_driver_per_team.rename(columns={\"name\": \"team_name\"})\n",
        "\n",
        "# Display top drivers per team\n",
        "print(top_driver_per_team[[\"team_name\", \"driver_name\", \"points\"]])\n"
      ],
      "metadata": {
        "id": "q_Ajx2myOjsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute constructor standings before swap\n",
        "constructor_standings_before = results.groupby(\"constructorId\")[\"points\"].sum().reset_index()\n",
        "constructor_standings_before = constructor_standings_before.merge(constructors[[\"constructorId\", \"name\"]], on=\"constructorId\", how=\"left\")\n",
        "constructor_standings_before = constructor_standings_before.rename(columns={\"points\": \"team_points_before\", \"name\": \"team_name\"})\n",
        "\n",
        "# Compute driver standings before swap\n",
        "driver_standings_before = results.groupby(\"driverId\")[\"points\"].sum().reset_index()\n",
        "driver_standings_before = driver_standings_before.merge(drivers[[\"driverId\", \"forename\", \"surname\"]], on=\"driverId\", how=\"left\")\n",
        "driver_standings_before[\"driver_name\"] = driver_standings_before[\"forename\"] + \" \" + driver_standings_before[\"surname\"]\n",
        "driver_standings_before = driver_standings_before.rename(columns={\"points\": \"driver_points_before\"})\n",
        "\n",
        "# Sort standings before swap\n",
        "constructor_standings_before = constructor_standings_before.sort_values(by=\"team_points_before\", ascending=False).reset_index(drop=True)\n",
        "driver_standings_before = driver_standings_before.sort_values(by=\"driver_points_before\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "# Display before swap standings\n",
        "print(\"Constructor Standings Before Swap:\")\n",
        "print(constructor_standings_before[[\"team_name\", \"team_points_before\"]].head(10))  # Show top 10\n",
        "\n",
        "print(\"\\nDriver Standings Before Swap:\")\n",
        "print(driver_standings_before[[\"driver_name\", \"driver_points_before\"]].head(10))  # Show top 10\n"
      ],
      "metadata": {
        "id": "mIZBlkF_ROSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select two teams for the swap\n",
        "team_A = top_driver_per_team.iloc[0]  # Example: First team\n",
        "team_B = top_driver_per_team.iloc[1]  # Example: Second team\n",
        "\n",
        "print(f\"Swapping {team_A['driver_name']} (from {team_A['team_name']}) with {team_B['driver_name']} (from {team_B['team_name']})\")\n"
      ],
      "metadata": {
        "id": "jiG5rddXOqi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a copy to modify\n",
        "swapped_results = results.copy()\n",
        "\n",
        "# Swap team associations for the selected drivers\n",
        "swapped_results.loc[swapped_results[\"driverId\"] == team_A[\"driverId\"], \"constructorId\"] = team_B[\"constructorId\"]\n",
        "swapped_results.loc[swapped_results[\"driverId\"] == team_B[\"driverId\"], \"constructorId\"] = team_A[\"constructorId\"]\n"
      ],
      "metadata": {
        "id": "GyIFnNxSOsYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recalculate team standings\n",
        "team_standings = swapped_results.groupby(\"constructorId\")[\"points\"].sum().reset_index()\n",
        "team_standings = team_standings.merge(constructors, on=\"constructorId\", how=\"left\")\n",
        "team_standings = team_standings.rename(columns={\"name\": \"team_name\"}).sort_values(\"points\", ascending=False)\n",
        "\n",
        "# Recalculate driver standings\n",
        "driver_standings = swapped_results.groupby(\"driverId\")[\"points\"].sum().reset_index()\n",
        "driver_standings = driver_standings.merge(drivers, on=\"driverId\", how=\"left\")\n",
        "driver_standings[\"driver_name\"] = driver_standings[\"forename\"] + \" \" + driver_standings[\"surname\"]\n",
        "driver_standings = driver_standings.sort_values(\"points\", ascending=False)\n",
        "\n",
        "# Compare before and after\n",
        "print(\"\\nTeam Standings After Swap:\")\n",
        "print(team_standings[[\"team_name\", \"points\"]].head(10))\n",
        "\n",
        "print(\"\\nDriver Standings After Swap:\")\n",
        "print(driver_standings[[\"driver_name\", \"points\"]].head(10))\n"
      ],
      "metadata": {
        "id": "6QAUpUEqOvhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Merge before and after standings for teams\n",
        "team_comparison = constructor_standings_before.merge(team_standings, on=\"team_name\", suffixes=(\"_before\", \"_after\"))\n",
        "\n",
        "# Merge before and after standings for drivers\n",
        "driver_comparison = driver_standings_before.merge(driver_standings, on=\"driver_name\", suffixes=(\"_before\", \"_after\"))\n",
        "\n",
        "# Limit to Top 10 Teams & Drivers\n",
        "team_comparison = team_comparison.head(10)\n",
        "driver_comparison = driver_comparison.head(10)\n",
        "\n",
        "# Set up figure\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# **Team Standings Bar Plot**\n",
        "team_comparison_melted = team_comparison.melt(id_vars=\"team_name\", value_vars=[\"team_points_before\", \"points\"],\n",
        "                                              var_name=\"Status\", value_name=\"Total Points\")\n",
        "\n",
        "sns.barplot(x=\"Total Points\", y=\"team_name\", hue=\"Status\", data=team_comparison_melted, palette=[\"#FF9999\", \"#66B2FF\"], ax=axes[0])\n",
        "axes[0].set_title(\"Team Standings: Before vs. After Swap\")\n",
        "axes[0].set_xlabel(\"Total Points\")\n",
        "axes[0].set_ylabel(\"Team Name\")\n",
        "\n",
        "# **Driver Standings Bar Plot**\n",
        "driver_comparison_melted = driver_comparison.melt(id_vars=\"driver_name\", value_vars=[\"driver_points_before\", \"points\"],\n",
        "                                                  var_name=\"Status\", value_name=\"Total Points\")\n",
        "\n",
        "sns.barplot(x=\"Total Points\", y=\"driver_name\", hue=\"Status\", data=driver_comparison_melted, palette=[\"#FF9999\", \"#66B2FF\"], ax=axes[1])\n",
        "axes[1].set_title(\"Driver Standings: Before vs. After Swap\")\n",
        "axes[1].set_xlabel(\"Total Points\")\n",
        "axes[1].set_ylabel(\"Driver Name\")\n",
        "\n",
        "# Show the plots\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xmc933j1R3BO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PS - 6**"
      ],
      "metadata": {
        "id": "sTIbNGBmbMjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Driver Movements & Team Networks:\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load Dataset\n",
        "race_results = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/results.csv\")\n",
        "races = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/races.csv\")\n",
        "\n",
        "# Merge race year into race_results\n",
        "race_results = race_results.merge(races[['raceId', 'year']], on='raceId', how='left')\n",
        "\n",
        "# Select a year range (e.g., 2000-2010)\n",
        "start_year, end_year = 2000, 2020\n",
        "race_results = race_results[(race_results['year'] >= start_year) & (race_results['year'] <= end_year)]\n",
        "\n",
        "# Get the top performer (highest points) per year within the range\n",
        "top_drivers_per_year = race_results.loc[race_results.groupby('year')['points'].idxmax()]\n",
        "top_drivers_per_year = top_drivers_per_year[['year', 'driverId', 'constructorId']]\n",
        "\n",
        "# Create Graph\n",
        "G = nx.DiGraph()\n",
        "\n",
        "# Add edges (Driver -> Team per year)\n",
        "for _, row in top_drivers_per_year.iterrows():\n",
        "    year, driver, team = row\n",
        "    driver_label = f\"Driver {driver} ({year})\"\n",
        "    team_label = f\"Team {team} ({year})\"\n",
        "    G.add_edge(driver_label, team_label)\n",
        "\n",
        "# Draw Network Graph using Kamada-Kawai Layout\n",
        "plt.figure(figsize=(16, 10))\n",
        "pos = nx.spring_layout(G, seed=42)  # Layout positioning\n",
        "\n",
        "# Draw nodes with different colors for clarity\n",
        "nx.draw_networkx_nodes(G, pos, node_size=800, node_color=\"skyblue\", alpha=0.8)\n",
        "nx.draw_networkx_edges(G, pos, edge_color=\"gray\", alpha=0.6, connectionstyle=\"arc3,rad=0.1\")  # Curved edges\n",
        "nx.draw_networkx_labels(G, pos, font_size=9, font_weight=\"bold\", verticalalignment='center', bbox=dict(facecolor=\"white\", alpha=0.6, edgecolor=\"none\"))\n",
        "\n",
        "# Title and display\n",
        "plt.title(f\"Top Performers' Movements Across Teams ({start_year}-{end_year})\", fontsize=14)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "uQYoT69-bfyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PS - 7**"
      ],
      "metadata": {
        "id": "IRusn5jAbS6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Team Performance Comparison:\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Load Datasets\n",
        "results = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/results.csv\")\n",
        "races = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/races.csv\")\n",
        "constructors = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/constructors.csv\")\n",
        "\n",
        "# Merge team (constructor) names\n",
        "results = results.merge(constructors[['constructorId', 'name']], on='constructorId', how='left')\n",
        "\n",
        "# Merge race year and circuitId\n",
        "results = results.merge(races[['raceId', 'year', 'circuitId']], on='raceId', how='left')\n",
        "\n",
        "# Filter Data for Specific Years (e.g., 2000-2010)\n",
        "start_year = 2000\n",
        "end_year = 2010\n",
        "results = results[(results['year'] >= start_year) & (results['year'] <= end_year)]\n",
        "\n",
        "# Filter for P1 finishes (Wins)\n",
        "winners = results[results['positionOrder'] == 1]\n",
        "\n",
        "# Compute success rate (Without Circuit Factor)\n",
        "team_win_counts = winners['name'].value_counts()\n",
        "team_total_races = results['name'].value_counts()\n",
        "team_win_rates = (team_win_counts / team_total_races).fillna(0) * 100  # Convert to percentage\n",
        "\n",
        "# âœ… Select Only the **Top 10 Teams** for Clarity\n",
        "top_teams = team_win_rates.nlargest(10).index\n",
        "team_win_rates = team_win_rates.loc[top_teams]\n",
        "\n",
        "# Compute success rate (With Circuit Factor) for Top Teams Only\n",
        "circuit_wins = winners[winners['name'].isin(top_teams)].groupby(['circuitId', 'name']).size().unstack(fill_value=0)\n",
        "circuit_total_races = results[results['name'].isin(top_teams)].groupby(['circuitId', 'name']).size().unstack(fill_value=0)\n",
        "circuit_win_rates = (circuit_wins / circuit_total_races).fillna(0) * 100  # Convert to percentage\n",
        "\n",
        "# âœ… Compute Average Win Rate **Considering Circuits**\n",
        "avg_circuit_win_rates = circuit_win_rates.mean(axis=0).reindex(top_teams).fillna(0)\n",
        "\n",
        "# ðŸŽ¯ Grouped Bar Chart\n",
        "x = np.arange(len(top_teams))  # Bar positions\n",
        "width = 0.4  # Width of bars\n",
        "\n",
        "plt.figure(figsize=(14, 7))\n",
        "\n",
        "# Overall Win Rate\n",
        "plt.bar(x - width/2, team_win_rates.values, width, label=\"Win Rate without circuit\", color=\"royalblue\")\n",
        "\n",
        "# Circuit-Specific Win Rate\n",
        "plt.bar(x + width/2, avg_circuit_win_rates.values, width, label=\"Win Rate with circuit\", color=\"orange\")\n",
        "\n",
        "# Formatting\n",
        "plt.xticks(x, top_teams, rotation=45, ha=\"right\")\n",
        "plt.ylabel(\"Win Rate (%)\")\n",
        "plt.title(f\"Win Rates Comparison: With vs Without Circuit Factor ({start_year}-{end_year})\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "gxFETz6Lb-Mo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PS - 8**"
      ],
      "metadata": {
        "id": "wR3X-pWCbWhE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Driver Consistency in Race Performance:\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# Load Dataset\n",
        "race_results = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/results.csv\")\n",
        "\n",
        "# Keep relevant columns\n",
        "race_results = race_results[['driverId', 'raceId', 'positionOrder']]\n",
        "\n",
        "# Define a top finish (Top 3)\n",
        "race_results['top_finish'] = race_results['positionOrder'] <= 3\n",
        "\n",
        "# Calculate consistency metrics\n",
        "driver_stats = race_results.groupby('driverId').agg(\n",
        "    total_races=('raceId', 'count'),\n",
        "    top_finishes=('top_finish', 'sum'),\n",
        "    avg_position=('positionOrder', 'mean'),\n",
        "    position_std=('positionOrder', 'std')  # Variance in finishing positions\n",
        ").reset_index()\n",
        "\n",
        "# Compute Top Finish Rate (% of races in Top 3)\n",
        "driver_stats['top_finish_rate'] = driver_stats['top_finishes'] / driver_stats['total_races']\n",
        "\n",
        "# Identify consistent vs. inconsistent drivers\n",
        "consistent_drivers = driver_stats.sort_values(by='top_finish_rate', ascending=False).head(10)\n",
        "inconsistent_drivers = driver_stats.sort_values(by='position_std', ascending=False).head(10)\n",
        "\n",
        "# ðŸ“Š Plotting Consistent Drivers\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(consistent_drivers['driverId'].astype(str), consistent_drivers['top_finish_rate'], color='green', alpha=0.7)\n",
        "plt.xlabel(\"Driver ID\")\n",
        "plt.ylabel(\"Top Finish Rate\")\n",
        "plt.title(\"Top 10 Most Consistent Drivers (Top 3 Finish Rate)\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Select top drivers based on total races\n",
        "top_drivers = driver_stats.sort_values(by=\"total_races\", ascending=False).head(10)['driverId']\n",
        "\n",
        "# Filter results for top drivers\n",
        "top_driver_results = race_results[race_results['driverId'].isin(top_drivers)]\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x=top_driver_results[\"driverId\"].astype(str), y=top_driver_results[\"positionOrder\"], palette=\"coolwarm\")\n",
        "plt.xlabel(\"Driver ID\")\n",
        "plt.ylabel(\"Finishing Position (Lower is Better)\")\n",
        "plt.title(\"Driver Performance Consistency (Top 10 Drivers by Races)\")\n",
        "plt.gca().invert_yaxis()  # Flip so 1st place is at the top\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LlO6E06tcBch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PS - 9**"
      ],
      "metadata": {
        "id": "SRbaq6Vibaoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load datasets\n",
        "laps = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/lap_times.csv\")\n",
        "results = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/results.csv\")\n",
        "constructors = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/constructors.csv\")\n",
        "races = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/races.csv\")\n",
        "\n",
        "# Merge lap times with race info\n",
        "lap_data = laps.merge(races[[\"raceId\", \"circuitId\"]], on=\"raceId\", how=\"left\")\n",
        "\n",
        "# Merge with constructor details via results dataset\n",
        "lap_data = lap_data.merge(results[[\"raceId\", \"driverId\", \"constructorId\"]], on=[\"raceId\", \"driverId\"], how=\"left\")\n",
        "lap_data = lap_data.merge(constructors[[\"constructorId\", \"name\"]], on=\"constructorId\", how=\"left\")\n",
        "\n",
        "# Convert lap times to numeric format\n",
        "lap_data[\"milliseconds\"] = pd.to_numeric(lap_data[\"milliseconds\"], errors=\"coerce\")\n"
      ],
      "metadata": {
        "id": "3VZeEtuacqE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by circuit and team to compute average lap time\n",
        "team_efficiency = lap_data.groupby([\"circuitId\", \"name\"])[\"milliseconds\"].mean().reset_index()\n",
        "\n",
        "# Rename for clarity\n",
        "team_efficiency = team_efficiency.rename(columns={\"name\": \"team_name\", \"milliseconds\": \"avg_lap_time\"})\n",
        "\n",
        "# Sort by efficiency (fastest teams per circuit)\n",
        "team_efficiency = team_efficiency.sort_values([\"circuitId\", \"avg_lap_time\"])\n"
      ],
      "metadata": {
        "id": "GTKUhkAMcrFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the best (fastest) team for each circuit\n",
        "best_teams_per_circuit = team_efficiency.loc[team_efficiency.groupby(\"circuitId\")[\"avg_lap_time\"].idxmin()]\n",
        "\n",
        "# Merge with circuit names\n",
        "circuits = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/circuits.csv\")\n",
        "best_teams_per_circuit = best_teams_per_circuit.merge(circuits[[\"circuitId\", \"name\"]], on=\"circuitId\", how=\"left\")\n",
        "best_teams_per_circuit = best_teams_per_circuit.rename(columns={\"name\": \"circuit_name\"})\n"
      ],
      "metadata": {
        "id": "idUvIR35ct1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=\"avg_lap_time\", y=\"circuit_name\", hue=\"team_name\", data=best_teams_per_circuit, palette=\"coolwarm\")\n",
        "\n",
        "plt.title(\"Most Efficient Teams Across Circuits (Fastest Average Lap Times)\")\n",
        "plt.xlabel(\"Average Lap Time (ms)\")\n",
        "plt.ylabel(\"Circuit Name\")\n",
        "plt.legend(title=\"Team\")\n",
        "plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.7)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Tbd1cTeecvzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the overall average lap time per team\n",
        "team_avg_lap_times = best_teams_per_circuit.groupby(\"team_name\")[\"avg_lap_time\"].mean().reset_index()\n",
        "\n",
        "# Sort teams by lap time (ascending order for efficiency)\n",
        "team_avg_lap_times = team_avg_lap_times.sort_values(\"avg_lap_time\")\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=\"avg_lap_time\", y=\"team_name\", data=team_avg_lap_times, palette=\"coolwarm\")\n",
        "\n",
        "plt.title(\"Most Efficient Teams (Lowest Average Lap Time)\")\n",
        "plt.xlabel(\"Average Lap Time (ms)\")\n",
        "plt.ylabel(\"Team Name\")\n",
        "plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.7)\n",
        "plt.show()\n",
        "\n",
        "# Get the most efficient team\n",
        "most_efficient_team = team_avg_lap_times.iloc[0]\n",
        "print(f\"Most Efficient Team: {most_efficient_team['team_name']} \\n Average lap time: {most_efficient_team['avg_lap_time']:.2f} ms\")\n"
      ],
      "metadata": {
        "id": "ZEqiBg9ufBn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PS - 10**"
      ],
      "metadata": {
        "id": "6aFl2O_Ubetz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "results = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/results.csv\")\n",
        "races = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/races.csv\")\n",
        "drivers = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/drivers.csv\")\n",
        "\n",
        "results = results.merge(races[['raceId', 'year']], on='raceId', how='left')\n",
        "recent_results = results[results['year'] >= 2020]\n",
        "\n",
        "driver_perf = recent_results.groupby('driverId').agg(\n",
        "    total_points=('points', 'sum'),\n",
        "    wins=('positionOrder', lambda x: (x == 1).sum()),\n",
        "    podiums=('positionOrder', lambda x: (x <= 3).sum()),\n",
        "    races=('raceId', 'nunique')\n",
        ").reset_index()\n",
        "\n",
        "driver_perf = driver_perf.merge(drivers[['driverId', 'forename', 'surname']], on='driverId', how='left')\n",
        "driver_perf['driver'] = driver_perf['forename'] + \" \" + driver_perf['surname']\n",
        "driver_perf['composite_score'] = driver_perf['total_points'] + 50 * driver_perf['wins'] + 20 * driver_perf['podiums']\n",
        "\n",
        "best_lineup = driver_perf.sort_values('composite_score', ascending=False).head(4)\n",
        "\n",
        "print(\"Best Team Lineup (Top 4 Drivers):\")\n",
        "print(best_lineup[['driver', 'total_points', 'wins', 'podiums', 'races', 'composite_score']])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TFSGiDg8fFff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PS - 11**"
      ],
      "metadata": {
        "id": "rTzn3LH7bjtF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#PREDICTION FOR 2025 SEASONS\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "results = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/results.csv\")\n",
        "races = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/races.csv\")\n",
        "drivers = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/drivers.csv\")\n",
        "constructors = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/constructors.csv\")\n",
        "\n",
        "results = results.merge(races[['raceId', 'year']], on='raceId', how='left')\n",
        "recent_results = results[results['year'] >= 2020]\n",
        "\n",
        "driver_points = recent_results.groupby(['year', 'driverId'])['points'].sum().reset_index()\n",
        "driver_avg = driver_points.groupby('driverId')['points'].mean().reset_index().rename(columns={'points': 'avg_points'})\n",
        "driver_avg = driver_avg.merge(drivers[['driverId', 'forename', 'surname']], on='driverId', how='left')\n",
        "driver_avg['driver'] = driver_avg['forename'] + \" \" + driver_avg['surname']\n",
        "predicted_driver = driver_avg.sort_values('avg_points', ascending=False).iloc[0]\n",
        "\n",
        "print(\"Predicted Drivers' Champion for 2025:\", predicted_driver['driver'])\n",
        "print(\"Average Points:\", predicted_driver['avg_points'])\n",
        "\n",
        "top10_drivers = driver_avg.sort_values('avg_points', ascending=False).head(10)\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(data=top10_drivers, x='avg_points', y='driver', palette='viridis')\n",
        "plt.title(\"Top 10 Drivers by Average Points (2020+)\\nPredicted Champion: \" + predicted_driver['driver'])\n",
        "plt.xlabel(\"Average Points\")\n",
        "plt.ylabel(\"Driver\")\n",
        "plt.show()\n",
        "\n",
        "constructor_points = recent_results.groupby(['year', 'constructorId'])['points'].sum().reset_index()\n",
        "constructor_avg = constructor_points.groupby('constructorId')['points'].mean().reset_index().rename(columns={'points': 'avg_points'})\n",
        "constructor_avg = constructor_avg.merge(constructors[['constructorId', 'name']], on='constructorId', how='left')\n",
        "predicted_constructor = constructor_avg.sort_values('avg_points', ascending=False).iloc[0]\n",
        "\n",
        "print(\"Predicted Constructors' Champion for 2025:\", predicted_constructor['name'])\n",
        "print(\"Average Points:\", predicted_constructor['avg_points'])\n",
        "\n",
        "top10_constructors = constructor_avg.sort_values('avg_points', ascending=False).head(10)\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(data=top10_constructors, x='avg_points', y='name', palette='magma')\n",
        "plt.title(\"Top 10 Constructors by Average Points (2020+)\\nPredicted Champion: \" + predicted_constructor['name'])\n",
        "plt.xlabel(\"Average Points\")\n",
        "plt.ylabel(\"Constructor\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kXPLjqFeQm8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PS - 12**"
      ],
      "metadata": {
        "id": "TzRQEQ81bqDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Struggling Teams Analysis:\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "results = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/results.csv\")\n",
        "races = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/races.csv\")\n",
        "constructors = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/constructors.csv\")\n",
        "\n",
        "results = results.merge(races[['raceId','year']], on='raceId', how='left')\n",
        "recent_results = results[results['year'] >= 2020]\n",
        "constructor_points = recent_results.groupby(['year','constructorId'])['points'].sum().reset_index()\n",
        "constructor_avg = constructor_points.groupby('constructorId')['points'].mean().reset_index().rename(columns={'points':'avg_points'})\n",
        "constructor_avg = constructor_avg.merge(constructors[['constructorId','name']], on='constructorId', how='left')\n",
        "predicted_struggling = constructor_avg.sort_values('avg_points', ascending=True).iloc[0]\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(data=constructor_avg.sort_values('avg_points'), x='avg_points', y='name', palette='coolwarm')\n",
        "plt.title(\"Average Points of Constructors (2020+)\\nPredicted Underperformer: \" + predicted_struggling['name'])\n",
        "plt.xlabel(\"Average Points\")\n",
        "plt.ylabel(\"Constructor\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6MYjz6hfRfqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PS - 13**"
      ],
      "metadata": {
        "id": "y15VC6wPbuOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Driver-Specific Track Struggles\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "results = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/results.csv\")\n",
        "races = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/races.csv\")\n",
        "circuits = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/circuits.csv\")\n",
        "\n",
        "results_races = results.merge(races[['raceId','circuitId']], on='raceId', how='left')\n",
        "driver_circuit = results_races.groupby(['driverId','circuitId'])['positionOrder'].mean().reset_index()\n",
        "driver_id = 1  # Change as needed\n",
        "driver_perf = driver_circuit[driver_circuit['driverId'] == driver_id]\n",
        "driver_perf = driver_perf.merge(circuits[['circuitId','name']], on='circuitId', how='left')\n",
        "driver_perf = driver_perf.sort_values('positionOrder')\n",
        "\n",
        "plt.figure(figsize=(24,6))\n",
        "sns.barplot(data=driver_perf, x='name', y='positionOrder', palette='viridis')\n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Driver \" + str(driver_id) + \" Average Finishing Positions by Circuit\")\n",
        "plt.xlabel(\"Circuit\")\n",
        "plt.ylabel(\"Average Finishing Position\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "fFYxtHJIR89u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PS - 14**"
      ],
      "metadata": {
        "id": "VSFZzFO3b3jI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Championship Retention Probability\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "results = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/results.csv\")\n",
        "races = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/races.csv\")\n",
        "\n",
        "results = results.merge(races[['raceId','year']], on='raceId', how='left')\n",
        "driver_points = results.groupby(['year','driverId'])['points'].sum().reset_index()\n",
        "season_champs = driver_points.loc[driver_points.groupby('year')['points'].idxmax()].sort_values('year')\n",
        "season_champs['retained'] = season_champs['driverId'].shift() == season_champs['driverId']\n",
        "retention_rate = season_champs['retained'].mean()\n",
        "\n",
        "retained_count = season_champs['retained'].sum()\n",
        "not_retained_count = len(season_champs) - retained_count\n",
        "labels = ['Retained', 'Not Retained']\n",
        "sizes = [retained_count, not_retained_count]\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.pie(sizes, labels=labels, autopct='%1.1f%%', colors=['#66b3ff', '#ff9999'])\n",
        "plt.title(\"Championship Retention Distribution\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.lineplot(data=season_champs, x='year', y='points', marker='o', color='darkgreen')\n",
        "plt.title(\"Champion Points over Seasons\")\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Champion Points\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Historical Championship Retention Rate:\", retention_rate)\n"
      ],
      "metadata": {
        "id": "qzemHk1NSIS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PS - 15**"
      ],
      "metadata": {
        "id": "kRbmB2slb7dv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Champion Age Trends\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "results = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/results.csv\")\n",
        "races = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/races.csv\")\n",
        "drivers = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/drivers.csv\")\n",
        "\n",
        "results = results.merge(races[['raceId','year']], on='raceId', how='left')\n",
        "driver_points = results.groupby(['year','driverId'])['points'].sum().reset_index()\n",
        "season_champs = driver_points.loc[driver_points.groupby('year')['points'].idxmax()].sort_values('year')\n",
        "drivers['dob'] = pd.to_datetime(drivers['dob'], errors='coerce')\n",
        "season_champs = season_champs.merge(drivers[['driverId','dob']], on='driverId', how='left')\n",
        "season_champs['age'] = season_champs['year'] - season_champs['dob'].dt.year\n",
        "season_champs['decade'] = (season_champs['year'] // 10) * 10\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.boxplot(x='decade', y='age', data=season_champs, palette='Set3')\n",
        "plt.title(\"Champion Age Trends by Decade\")\n",
        "plt.xlabel(\"Decade\")\n",
        "plt.ylabel(\"Champion Age\")\n",
        "plt.show()\n",
        "\n",
        "age_trends = season_champs.groupby('decade')['age'].describe()\n",
        "print(\"Champion Age Trends by Decade:\")\n",
        "print(age_trends)\n"
      ],
      "metadata": {
        "id": "u9DRK2e8SSaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PS - 16**"
      ],
      "metadata": {
        "id": "k-kCF-Tib-sf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load datasets\n",
        "results = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/results.csv\")\n",
        "races = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/races.csv\")\n",
        "constructors = pd.read_csv(\"/content/drive/My Drive/DPL_Datasets/constructors.csv\")\n",
        "\n",
        "# Merge race info and prepare driver-team history\n",
        "results = results.merge(races[['raceId', 'year']], on='raceId', how='left')\n",
        "driver_teams = results[['year', 'driverId', 'constructorId']].drop_duplicates().sort_values(['driverId', 'year'])\n",
        "driver_transitions = driver_teams.groupby('driverId')['constructorId'].apply(list).reset_index()\n",
        "\n",
        "# Build the directed graph of team transitions\n",
        "G = nx.DiGraph()\n",
        "transition_counts = {}\n",
        "\n",
        "for _, row in driver_transitions.iterrows():\n",
        "    teams = row['constructorId']\n",
        "    if len(teams) > 1:\n",
        "        for i in range(len(teams) - 1):\n",
        "            if G.has_edge(teams[i], teams[i+1]):\n",
        "                G[teams[i]][teams[i+1]]['weight'] += 1\n",
        "            else:\n",
        "                G.add_edge(teams[i], teams[i+1], weight=1)\n",
        "            transition_counts[teams[i]] = transition_counts.get(teams[i], 0) + 1\n",
        "\n",
        "# Map team IDs to team names\n",
        "team_names = constructors.set_index('constructorId')['name'].to_dict()\n",
        "labels = {node: team_names.get(node, str(node)) for node in G.nodes()}\n",
        "\n",
        "# Use Spring layout for better spacing\n",
        "pos = nx.spring_layout(G, k=1.2, seed=42)  # 'k' controls node spacing\n",
        "\n",
        "# Scale node sizes based on number of transitions\n",
        "node_sizes = [transition_counts.get(node, 1) * 50 for node in G.nodes()]\n",
        "\n",
        "# Reduce opacity of less frequent edges\n",
        "edges = G.edges(data=True)\n",
        "edge_weights = [data['weight'] for (_, _, data) in edges]\n",
        "edge_widths = [0.3 * w for w in edge_weights]  # Thinner edges\n",
        "edge_colors = ['gray' if w < 5 else 'black' for w in edge_weights]  # Highlight frequent moves\n",
        "\n",
        "# Use distinct colors for nodes\n",
        "cmap = plt.get_cmap('tab20')\n",
        "color_map = {node: cmap(i % 20) for i, node in enumerate(G.nodes())}\n",
        "\n",
        "# Plot the refined graph\n",
        "plt.figure(figsize=(16, 12))\n",
        "nx.draw_networkx_nodes(G, pos,\n",
        "                       node_color=[color_map[node] for node in G.nodes()],\n",
        "                       node_size=node_sizes,\n",
        "                       alpha=0.85)\n",
        "nx.draw_networkx_edges(G, pos,\n",
        "                       arrowstyle='->',\n",
        "                       arrowsize=15,\n",
        "                       edge_color=edge_colors,\n",
        "                       width=edge_widths,\n",
        "                       alpha=0.6)\n",
        "\n",
        "important_labels = {k: v for k, v in labels.items() if transition_counts.get(k, 0) > 5}\n",
        "nx.draw_networkx_labels(G, pos, important_labels, font_size=10, font_color='black')\n",
        "\n",
        "plt.title(\"Driver Team Transfer Trends\", fontsize=18, fontweight='bold')\n",
        "plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "p__QBuakmDxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Markov chain future predictions\n",
        "\n",
        "team_list = list(G.nodes())\n",
        "transition_matrix = np.zeros((len(team_list), len(team_list)))\n",
        "\n",
        "# Build transition probabilities\n",
        "for i, team1 in enumerate(team_list):\n",
        "    total_transitions = sum([G[team1][team2]['weight'] for team2 in G.successors(team1)])\n",
        "    for j, team2 in enumerate(team_list):\n",
        "        if G.has_edge(team1, team2):\n",
        "            transition_matrix[i, j] = G[team1][team2]['weight'] / total_transitions\n",
        "\n",
        "# Convert to DataFrame\n",
        "transition_df = pd.DataFrame(transition_matrix, index=team_list, columns=team_list)\n",
        "\n",
        "# Function to predict the next team\n",
        "def predict_next_team(current_team):\n",
        "    if current_team not in transition_df.index:\n",
        "        return \"No transition data available\"\n",
        "    next_team = transition_df.loc[current_team].idxmax()\n",
        "    return team_names.get(next_team, \"Unknown Team\")\n",
        "\n",
        "# Example Prediction: Predict the next team for a driver\n",
        "driver_name = \"Jarno\"  # Try different surnames like \"Hamilton\", \"Verstappen\"\n",
        "\n",
        "# Find the driver ID from their name\n",
        "driver_row = drivers[drivers[\"forename\"].str.lower() == driver_name.lower()]\n",
        "if not driver_row.empty:\n",
        "    driver_id = driver_row.iloc[0][\"driverId\"]\n",
        "    driver_team_history = driver_teams[driver_teams[\"driverId\"] == driver_id][\"constructorId\"].tolist()\n",
        "\n",
        "    if driver_team_history:\n",
        "        last_team = driver_team_history[-1]\n",
        "        predicted_team = predict_next_team(last_team)\n",
        "        print(f\"Predicted next team for {driver_name}: {predicted_team}\")\n",
        "    else:\n",
        "        print(f\"No team history available for {driver_name}\")\n",
        "else:\n",
        "    print(f\"Driver '{driver_name}' not found in the dataset.\")\n"
      ],
      "metadata": {
        "id": "-STLhOQnmPVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# team_names = dict(zip(constructors[\"constructorId\"], constructors[\"name\"]))\n",
        "# transition_df = transition_df.rename(index=team_names, columns=team_names)\n",
        "# print(transition_df)"
      ],
      "metadata": {
        "id": "aUgiJczsn6IB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}